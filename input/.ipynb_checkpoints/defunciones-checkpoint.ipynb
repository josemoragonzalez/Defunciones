{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicando análisis de mortalidad de COVID para Chile\n",
    "El siguiente notebook tiene como objetivo replicar el análisis realizado por The Economist para la realidad de Chile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este análisis está inspirado en la publicación realizada por The Economist que pueden encontrar en **[AQUÍ](https://www.economist.com/graphic-detail/2020/04/03/covid-19s-death-toll-appears-higher-than-official-figures-suggest)**\n",
    "<img src=\"../img/img.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos históricos de mortalidad\n",
    "La búsqueda de datos sobre mortalidad resultó ser una difícil tarea, de hecho la data histórica desagregada a nivel granular de defunción anonimizada solo llega hasta 2017. Esto porque la data de defunciones que debe ser publicada por el Instituto Nacional de Estadísticas (INE) y por el Departamento de Estadísticas de Información de Salud (DEIS), tarda años en ser procesada y publicada.\n",
    "\n",
    "Para este análisis los datos fueron obtenidos desde la página **[DEIS](https://deis.minsal.cl/#datosabiertos)**, específicamente de la sección datos abiertos, el dataset se llama **[\"DEF_1990-2017\"](https://repositoriodeis.minsal.cl/DatosAbiertos/Vitales/DEF_1990-2017.rar)**\n",
    "\n",
    "A continuación se puede apreciar una muestra de los datos que contiene este dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga del archivo usando urllib\n",
    "\n",
    "# importamos las librerias necesarias\n",
    "import urllib.request\n",
    "import os \n",
    "\n",
    "if not (os.path.exists(\"DEF_1990-2017.rar\")):\n",
    "    url = 'https://repositoriodeis.minsal.cl/DatosAbiertos/Vitales/DEF_1990-2017.rar'\n",
    "    RARmort = urllib.request.urlretrieve(url, 'DEF_1990-2017.rar') # El archivo quedará almacenado en la misma carpeta que el notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "# Estas librerías probablemente no las tendrán instaladas por lo que les recomiendo \n",
    "# realizar una vez su ejecución quitando el comentario\n",
    "#!conda install --yes --prefix {sys.prefix} -c conda-forge patool\n",
    "\n",
    "#----------------------------------------------------\n",
    "# Descompresión del archivo y lectura en un dataframe\n",
    "#----------------------------------------------------\n",
    "\n",
    "# importamos las librerias necesarias\n",
    "import pandas as pd\n",
    "import patoolib\n",
    "import pandas as pd\n",
    "\n",
    "# La descompresion queda en el actual directorio\n",
    "cwd = os.path.abspath(os.getcwd())\n",
    "patoolib.extract_archive(\"DEF_1990-2017.rar\", outdir=cwd, verbosity=-1)\n",
    "\n",
    "# lectura del archivo csv con encoding cp1252, es importante el enconding sino la lectura falla\n",
    "defHist = pd.read_csv('DEF_1990-2017.csv', sep = \";\" , encoding='cp1252', low_memory=False)\n",
    "\n",
    "#Eliminamos los archivos que ya no usamos.\n",
    "os.remove('DEF_1990-2017.rar')\n",
    "os.remove('DEF_1990-2017.csv')\n",
    "os.remove('Ficha Dato Abierto Defunciones.xlsx')\n",
    "\n",
    "#Establecemos un display ridículamente alto para que podamos ver todas las columnas del dataset\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "\n",
    "#Luego revisamos visualmente las variables del dataset\n",
    "defHist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos de Población\n",
    "Los datos de población corresponden a una proyección de realizada por el INE en el informe \"CHILE Proyecciones y Estimaciones de Poblacion Total del Pais 1950-2050\", el cual se puede encontrar **[AQUÍ](http://estadistica.ssmso.cl/downloads/proyecciones/CHILE-Proyecciones-y-Estimaciones-de-Poblacion-Total-del-Pais-1950-2050.pdf)**\n",
    "\n",
    "A continuación se puede ver una muestra de esos datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con este dataset, vamos a incluir manual los datos de población, proyectada por el INE, estos están en pdf en \n",
    "# http://estadistica.ssmso.cl/downloads/proyecciones/CHILE-Proyecciones-y-Estimaciones-de-Poblacion-Total-del-Pais-1950-2050.pdf\n",
    "# se puede automatizar con tabula-py pero ante tan pocos datos y que no cambiarán, prefiero hacerlo manual.\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "proyPobla = pd.DataFrame(np.array([[1990, 13178782], [1991, 13422010], [1992, 13665241], [1993, 13908473], [1994, 14151708]\\\n",
    "                                   , [1995, 14394940], [1996, 14595504], [1997, 14796076], [1998, 14996647], [1999, 15197213]\\\n",
    "                                   , [2000, 15397784], [2001, 15571679], [2002, 15745583], [2003, 15919479],[2004, 16093378]\\\n",
    "                                   , [2005, 16267278], [2006, 16432674], [2007, 16598074], [2008, 16763470], [2009, 16928873]\\\n",
    "                                   , [2010, 17094270], [2011, 17248450], [2012, 17402630], [2013, 17556815], [2014, 17711004]\\\n",
    "                                   , [2015, 17865185], [2016, 18001964], [2017, 18138749], [2018,18275530],[2019,18412316],[2020,18549095]]),\n",
    "                   columns=['ANIO', 'POBLACION'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamiento de datos históricos y cálculo de defunciones por cada 100.000 habitantes\n",
    "\n",
    "Ya con la información de población, es posible estimar la tasa de mortalidad por cada 100.000 habitantes, y dado que tenemos datos desde 1990 generé una serie semanal de datos (podría ser diaria pero más delante se justificará porque no fue así), promediando las defunciones semanales de cada año, y calculé un intervalo de confianza para determinar posteriormente si la serie semanal 2020 tiene diferencias significativas. \n",
    "\n",
    "Esta sería una muestra del dataframe, donde:\n",
    "- mean: promedio semanal de tasa de defunción por cada 100.000 habitantes\n",
    "- hi = limite superior de intervalo de confianza (95%)\n",
    "- low = limite inferior de intervalo de confianza (95%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo primero es reducir el dataset a los campos que nos puedan ser útiles ya que son 100\n",
    "defuncionesHist = defHist[['ID_FALLECIDO','ANO_DEF', 'MES_DEF', 'DIA_DEF']]\n",
    "\n",
    "# generamos unmerge por año para unir los dos dataframes\n",
    "defConsol = defuncionesHist.merge(proyPobla, how = 'left', left_on ='ANO_DEF', right_on = 'ANIO')\n",
    "\n",
    "# agrupamos la cantidad de defunciones por año, día, mes\n",
    "agrupDefun = defuncionesHist.groupby(['ANO_DEF', 'MES_DEF', 'DIA_DEF'], as_index = False)['ID_FALLECIDO'].count()\n",
    "agrupDefun = agrupDefun.rename(columns={\"ID_FALLECIDO\": \"CANT_FALLECIDOS\"})\n",
    "\n",
    "# Unimos las tablas de pobalación y defunciones\n",
    "\n",
    "defConsol = agrupDefun.merge(proyPobla, how = 'left', left_on ='ANO_DEF', right_on = 'ANIO')\n",
    "\n",
    "#generamos el campo de \"defunciones por cada 100.000 habitantes\" y el campo SEMANA\n",
    "defConsol['DEF_X_10000'] = defConsol['CANT_FALLECIDOS'] / defConsol['POBLACION'] * 100000\n",
    "defConsol['Fecha'] = defConsol['ANO_DEF'].astype(str) + '-' + defConsol['MES_DEF'].astype(int).astype(str) + '-' +defConsol['DIA_DEF'].astype(int).astype(str)\n",
    "defConsol['Fecha'] = pd.to_datetime(defConsol['Fecha'])\n",
    "defConsol['week'] =  defConsol['Fecha'].dt.week\n",
    "\n",
    "#Finalmente agregamos por promedio de defuncion por 100.000 \n",
    "fPromFallecidos = defConsol.groupby(['week', 'ANO_DEF'], as_index = False)['DEF_X_10000'].sum()\n",
    "fPromFallecidos = fPromFallecidos.groupby(['week'], as_index = False)['DEF_X_10000'].agg(['mean', 'count', 'std'])\n",
    "\n",
    "fPromFallecidos = fPromFallecidos.reset_index()\n",
    "fPromFallecidos['hi'] = fPromFallecidos['mean'] + (1.96 * fPromFallecidos['std'] / np.sqrt(fPromFallecidos['count']))\n",
    "fPromFallecidos['low'] = fPromFallecidos['mean'] - (1.96 * fPromFallecidos['std'] / np.sqrt(fPromFallecidos['count']))\n",
    "fPromFallecidos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serie de defunciones 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lamentablemente aún no existen estadísticas diarias sobre defunciones reales, sin embargo, a partir del 15/05/2020 el Registro Civil liberó el dato de la cantidad diaria de inscripciones de defunción, que como ellos señalan en su [web]('https://estadisticas.sed.srcei.cl/defhst') \"Cabe señalar, que la fecha de inscripción, no representa la fecha de defunción de una persona.\", pero que podría servir como proxy de las defunciones reales, por ello hice una comparación de las defunciones reales versus las inscritas para establecer si es posible hacer esta aproximación.\n",
    "Asimismo, quiero hacer hincapié en que la información liberada está incompleta, ya que los certificados tienen **fecha de defunción**, pero esto **NO FUE PUBLICADO**, siendo que este dato genera una mejor estimación de la realidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partimos haciendo una copia del histórico, y filtrando que sea mayor al año más antiguo del que se publicó data del certificado el cual corresponde a 2010\n",
    "defuncionesHist2010 =  defuncionesHist.copy()\n",
    "defHist2010 = defuncionesHist2010[defuncionesHist2010['ANO_DEF'] >= 2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Vamos a dejar el DF en el mismo formato que los archivos descargables del SRCeI, \n",
    "# agregando por año, mes, día, la cantidad de fallecidos\n",
    "def2010 = defHist2010.groupby(by=['ANO_DEF', 'MES_DEF',\t'DIA_DEF'])['ID_FALLECIDO'].count().reset_index()\n",
    "\n",
    "# Creamos el campo id que corresponde a la fecha, y lo pasamos a formato fecha de pandas\n",
    "def2010['id'] = def2010['ANO_DEF'].astype(str) + '-' + def2010['MES_DEF'].astype(int).astype(str) + '-' +def2010['DIA_DEF'].astype(int).astype(str)\n",
    "def2010['id'] = pd.to_datetime(def2010['id'])\n",
    "\n",
    "# Renombramos el campo de conteo\n",
    "def2010 = def2010.rename(columns = {'ID_FALLECIDO': 'REAL'})\n",
    "\n",
    "# Esta parte aún no está automatizada con los archivos desde el origen, (tendrán que creerme que son los datos o \n",
    "# visitar el sitio https://estadisticas.sed.srcei.cl/defhst y comprobarlo por ustedes mismos), \n",
    "# quizás despues haga la automatización con Selenium\n",
    "# mientras quedarán en la carpeta certificados de este repositorio\n",
    "# Cargamos los df\n",
    "dfproxy = pd.DataFrame()\n",
    "\n",
    "for i in range(2010, 2018):\n",
    "    url = 'certificados/' + str(i) + '.xlsx'\n",
    "    dfproxy = dfproxy.append(pd.read_excel(url, encoding = 'cp-1252'))\n",
    "\n",
    "# Agregamos por año, mes y día la columna total, ya que en el archivo los datos vienen desagregados por comuna.\n",
    "dfproxyG = dfproxy.groupby(by = ['AÑO', 'MES', 'DIA'])['TOTAL'].sum().reset_index()\n",
    "\n",
    "# Al igual que con los datos históricos hacemos un id fecha para poder luego hacer el cruce\n",
    "dfproxyG['id'] = dfproxyG['AÑO'].astype(str) + '-' + dfproxyG['MES'].astype(int).astype(str) + '-' +dfproxyG['DIA'].astype(int).astype(str)\n",
    "dfproxyG['id'] = pd.to_datetime(dfproxyG['id'])\n",
    "\n",
    "# renombramos la columna de totalización\n",
    "dfproxyG = dfproxyG.rename(columns = {'TOTAL': 'PROXY'})\n",
    "\n",
    "#Lo primero que vamos a revisar es si al totalizar la cantidad de defunciones de ambos dataset, la diferencia es muy alta, pues de ser así no tendría sentido seguir con la aproximación.\n",
    "txt = 'Según datos históricos, entre 2010 y 2017 hubo ' \\\n",
    "+ def2010['REAL'].agg(['sum'])[0].astype(str) \\\n",
    "+ \" fallecidos, mientras que de acuerdo a los Certificados hubo \" \\\n",
    "+ dfproxyG['PROXY'].agg(['sum'])[0].astype(str) \\\n",
    "+ ' defunciones inscritas, lo anterior representa un ' \\\n",
    "+ str(round((dfproxyG['PROXY'].agg(['sum'])[0].astype(float) - def2010['REAL'].agg(['sum'])[0].astype(float))/def2010['REAL'].agg(['sum'])[0].astype(float) * 100.0, 2)) \\\n",
    "+ '% de sobreestimación si usamos el certificado sobre las defunciones reales'\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al menos en términos gruesos, las cifras son similares y el error pareciera no ser significativo.\n",
    "\n",
    "Ahora vamos a visualizar el comportamiento diario para ver si podemos realizar el análisis con esa temporalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTemp = def2010.merge(dfproxyG, how = 'left', right_on = 'id', left_on = 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gráfico 1: Comparación entre series diarias de defunciones, real versus las inscritas 2010 - 2017***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# GRÁFICO 1\n",
    "#-------------------------------------------\n",
    "# Librerías necesarias\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# inciamos el gráfico y sus ejes\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot('id', 'REAL', data=dfTemp, color='black')\n",
    "ax.plot('id', 'PROXY', data=dfTemp, color='red', alpha = 0.5)\n",
    "\n",
    "# formateamos la grilla\n",
    "ax.grid(False)\n",
    "\n",
    "# seteamos leyendas y título\n",
    "ax.set_xlabel('Fecha (diario)')\n",
    "ax.set_ylabel('Cantidad de defunciones por día')\n",
    "ax.set_title('Comparación diaria entre serie de defunciones reales versus inscripciones de defunciones')\n",
    "\n",
    "# tamaño del grafico\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "# color de los ejes \n",
    "ax.spines['bottom'].set_color('#cccccc')\n",
    "ax.spines['top'].set_color('#cccccc') \n",
    "ax.spines['right'].set_color('white')\n",
    "ax.spines['left'].set_color('white')\n",
    "ax.legend(('defunciones reales diarias', 'certificados de defunciones inscritos diarios')\n",
    "          , loc='lower left', shadow=False, fontsize = 13)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar en el gráfico 1 que los comportamientos de las series diarias son bastante disímiles, por lo que no es posible usar la data como proxy a este nivel, pues la aproximación presentaría mucho ruido.\n",
    "Frente a esta problemática, decidí pasar al siguiente nivel de agregación temporal, **semana**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el campo semana usando la función pandas para ello.\n",
    "dfTemp['week'] = dfTemp['id'].dt.week\n",
    "\n",
    "# agrupamos por semana y año\n",
    "toplot = dfTemp.groupby(by=['week', 'AÑO']).sum().reset_index()\n",
    "\n",
    "# eliminamos campos innecesarios\n",
    "toplot = toplot[['week', 'AÑO', 'REAL', 'PROXY']]\n",
    "\n",
    "# creamos un campo cualquiera para ordenar la serie\n",
    "toplot['x'] = toplot['AÑO'] * 100 + toplot['week']\n",
    "toplot = toplot.sort_values('x')\n",
    "toplot2 = toplot.reset_index().drop(columns = {'index'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gráfico 2: Comparación entre series semanales de defunciones,  real versus las inscritas 2010 - 2017***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# GRÁFICO 2\n",
    "#--------------------------------------------\n",
    "\n",
    "#Librerías necesarias\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#inciamos el gráfico y sus ejes\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(toplot2.index, 'REAL', data=toplot2, color='black')\n",
    "ax.plot(toplot2.index, 'PROXY', data=toplot2, color='red', alpha = 0.7)\n",
    "\n",
    "# formateamos la grilla\n",
    "ax.grid(False)\n",
    "\n",
    "# seteamos leyendas y título\n",
    "ax.set_xlabel('Índice ordenado desde 2010-01 hasta 2017-12')\n",
    "ax.set_ylabel('Cantidad de defunciones por semana')\n",
    "ax.set_title('Comparación semanal entre serie de defunciones reales versus inscripciones de defunciones')\n",
    "\n",
    "#tamaño del grafico\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "# color de los ejes \n",
    "ax.spines['bottom'].set_color('#cccccc')\n",
    "ax.spines['top'].set_color('#cccccc') \n",
    "ax.spines['right'].set_color('white')\n",
    "ax.spines['left'].set_color('white')\n",
    "ax.legend(('defunciones reales semanales', 'certificados de defunciones inscritos por semana')\n",
    "          , loc='lower left', shadow=False, fontsize = 13)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta vez vemos que en general tenemos comportamientos mucho más parecidos entre ambas series, por lo que haremos una prueba t para ver si podemos usar la proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos una copia de toplot\n",
    "error = toplot.copy()\n",
    "\n",
    "# importamos la librería stats\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# generamos las series\n",
    "s1 = error[['REAL']]\n",
    "s2 = error[['PROXY']]\n",
    "\n",
    "# aplicamos el test\n",
    "ttest_ind(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos un alto p-value, por lo que no se puede descartar que sus medias sean iguales. Calcularemos el promedio del error porcentual absoluto para tener una idea del error que podríamos estar cometiendo con la estimación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos la librería\n",
    "import math\n",
    "\n",
    "#Calculamos el error porcentual\n",
    "error['diff'] = abs(error['REAL'] - error['PROXY']) /  error['PROXY'] * 100\n",
    "print(error['diff'].agg(['mean', 'median', 'std']).astype(float))\n",
    "print(\"90th percentil: \" + str(error['diff'].quantile(.9)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, la verdad los resultados no son muy alentadores, ya que en promedio las series se diferncian un 5% una de otra, y pese a que un 50% de los datos no tengan un error mayor a 2,3%, para alcanzar un 90% vemos que eso sube a 8,4% que es un error considerable por día.\n",
    "De todas maneras realizaremos el ejercicio, pero con las precauciones que:\n",
    "\n",
    "- ### En términos gloables las diferencias son muy menores (0,56%)\n",
    "- ### En términos semanales las diferencias son considerables, pues un 90% de los datos difieren en un 8,4% o menos y en promedio difieren 2,3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "## CARGAMOS 2020 para hacer el ejercicio de aproximación\n",
    "#----------------------------------------------------------\n",
    "\n",
    "df2020 = pd.read_excel('certificados/2020.xlsx', encoding = 'cp-1252')\n",
    "# Agregamos por año, mes y día la columna total, ya que en el archivo los datos vienen desagregados por comuna.\n",
    "df2020 = df2020.groupby(by = ['AÑO', 'MES', 'DIA'])['TOTAL'].sum().reset_index()\n",
    "\n",
    "# Al igual que con los datos históricos hacemos un id fecha para poder luego hacer el cruce\n",
    "df2020['Fecha'] = df2020['AÑO'].astype(str) + '-' + df2020['MES'].astype(int).astype(str) + '-' +df2020['DIA'].astype(int).astype(str)\n",
    "df2020['Fecha'] = pd.to_datetime(df2020['Fecha'])\n",
    "\n",
    "# renombramos la columna de totalización\n",
    "df2020 = df2020.rename(columns = {'TOTAL': 'DEF2020'})\n",
    "# añadimos el dato de población \n",
    "df2020['poblacion'] = 18549095\n",
    "\n",
    "# Calculamos las defunciones por cada 100.000 habitantes \n",
    "df2020['DEF2020_10000'] = df2020['DEF2020'] / df2020['poblacion'] * 100000\n",
    "\n",
    "# añadimos la semana\n",
    "df2020['week'] =  df2020['Fecha'].dt.week\n",
    "\n",
    "#Finalmente agregamos por promedio de defuncion por 100.000 \n",
    "df2020C = df2020.groupby(['week'], as_index = False)['DEF2020_10000'].sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serie de datos de defunciones por COVID-19\n",
    "La serie de datos de defunciones por COVID-19 se extrae desde el repositorio del [Ministerio de Ciencia](https://github.com/MinCiencia/Datos-COVID19/tree/master/output) para COVID, específicamente el [producto 5](https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto5).\n",
    "Se agradece que hayan automatizado esta serie, pues en las primeras versiones de este análisis, lo tuve que hacer extrayendo desde el informe en PDF, usando tabula-py, y se rompía cada vez que cambiaban la tabla 1.\n",
    "\n",
    "A continuación podemos ver una muestra de esta serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "temp1 = pd.read_csv(\"https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto5/TotalesNacionales_T.csv\")\n",
    "\n",
    "temp1 = temp1[['Fecha', 'Fallecidos']]\n",
    "\n",
    "temp2 = pd.DataFrame()\n",
    "#Ciclo para llenar los dias sin datos\n",
    "for i in range(0, 62):\n",
    "    temp2 = temp2.append({'Fecha': datetime.date(2020, 1, 1) + datetime.timedelta(days=i), 'Fallecidos': 0}, ignore_index=True)\n",
    "    \n",
    "tempf = temp2.append(temp1, ignore_index = True)\n",
    "\n",
    "temporal = tempf.copy()\n",
    "for index, row in temporal.iterrows():\n",
    "    if(tempf['Fallecidos'][index] == 0):\n",
    "        temporal['Fallecidos'][index] = None\n",
    "\n",
    "    \n",
    "    else:\n",
    "        temporal['Fallecidos'][index] = tempf['Fallecidos'][index] - tempf['Fallecidos'][index - 1]\n",
    "\n",
    "temporal = temporal.rename(columns = {'Fallecidos': 'MuertesCOVID'})\n",
    "temporal['MuertesCOVID'] = temporal['MuertesCOVID'].fillna(0).astype(int)\n",
    "mCOVID = temporal.copy()\n",
    "mCOVID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "# Trabajo con dataset descargado\n",
    "#--------------------------------\n",
    "\n",
    "# Ahora que tenemos las muertes vamos a generar los datos para que sean graficables\n",
    "\n",
    "#Creamos el dataframe con solo los datos necesarios para el plot\n",
    "dfx = pd.DataFrame(columns = ['Fecha', 'binario'])\n",
    "\n",
    "#Ciclo para llenar los dias sin datos\n",
    "for i in range(0, 62):\n",
    "    dfx = dfx.append({'Fecha': datetime.date(2020, 1, 1) + datetime.timedelta(days=i), 'binario': 0}, ignore_index=True)\n",
    "\n",
    "for i in range(62, len(mCOVID)):\n",
    "    dfx = dfx.append({'Fecha': datetime.date(2020, 1, 1) + datetime.timedelta(days=i), 'binario': 1}, ignore_index=True)\n",
    "\n",
    "# Pasamos los datos de fecha a formato pandas\n",
    "dfx['Fecha'] = pd.to_datetime(dfx['Fecha'])\n",
    "mCOVID['Fecha'] = pd.to_datetime(mCOVID['Fecha'])\n",
    "\n",
    "# Unimos los datasets y agregamos el dato de población 2020 proyectada\n",
    "temp = dfx.merge(mCOVID, how = 'left', left_on = 'Fecha', right_on = 'Fecha')\n",
    "temp['poblacion'] = 18549095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos los mismo para datos de fecha de df2020\n",
    "temp['Fecha'] = pd.to_datetime(temp['Fecha'])\n",
    "\n",
    "# Calculamos las defunciones por cada 100.000 habitantes \n",
    "temp['DEFCOVID_10000'] = temp['MuertesCOVID'] / temp['poblacion'] * 100000\n",
    "\n",
    "# añadimos la semana\n",
    "temp['week'] =  temp['Fecha'].dt.week\n",
    "temp['week'] = temp['week'].fillna(max(temp['week'])) #TEMPORAL MIENTRAS ARREGLAN LA FUENTE DE DATOS\n",
    "\n",
    "#Finalmente agregamos por promedio de defuncion por 100.000 \n",
    "temp = temp.groupby(['week'], as_index = False)['DEFCOVID_10000'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculamos el la serie a graficar \n",
    "fCovid = temp.copy()\n",
    "\n",
    "#unimos con la serie histórica\n",
    "fCovid = fCovid.merge(fPromFallecidos, how= 'left', left_on = 'week', right_on = 'week')\n",
    "\n",
    "#Calculamos las series a graficar\n",
    "fCovid['DEFCOVID_10000'] = fCovid['mean'] + fCovid['DEFCOVID_10000']\n",
    "fCovid['hiCov'] = (fCovid['hi'] - fCovid['mean'] + fCovid['DEFCOVID_10000'])\n",
    "fCovid['lowCov'] = (fCovid['DEFCOVID_10000'] - (fCovid['mean'] - fCovid['low']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos todo en un gran dataset antes de graficar\n",
    "\n",
    "fCovidF = fCovid.merge(df2020C, how = 'left', left_on = 'week', right_on = 'week')\n",
    "fCovidF = fCovidF[['week', 'DEFCOVID_10000', 'mean', 'DEF2020_10000', 'hi',\t'low', 'hiCov', 'lowCov']]\n",
    "\n",
    "#reindexamos\n",
    "fCovidF.index = np.arange(1, len(fCovidF) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos manual la última semana porque no está completa\n",
    "fCovidF = fCovidF[:20][:]\n",
    "fCovidF['week'] =  fCovidF['week'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfico\n",
    "A continuación se presenta el gráfico con las tres series ya expuestas, presentadas en términos de defunciones diarias por cada 100.000 habitantes.\n",
    "\n",
    "***Gráfico 3: Evolución de defunciones promedio por cada 100.000 vs COVID-19 versus 2020 (ESTIMACION EN BASE A CERTIFICADO)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# GRÁFICO 3\n",
    "#--------------------------------------------\n",
    "\n",
    "#Librerías necesarias\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#inciamos el gráfico y sus ejes\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot('week', 'mean', data=fCovidF, color='black')\n",
    "ax.plot('week', 'DEFCOVID_10000', data=fCovidF, color='red')\n",
    "ax.plot('week', 'DEF2020_10000', data=fCovidF, color='blue')\n",
    "\n",
    "\n",
    "ax.fill_between(fCovidF.index, fCovidF.low, fCovidF.hi, facecolor='grey', alpha=.2)\n",
    "ax.fill_between(fCovidF.index, fCovidF.lowCov, fCovidF.hiCov, facecolor='red', alpha=.2)\n",
    "\n",
    "# delimitamos el eje y\n",
    "ax.set_ylim([0, np.nanmax(fCovidF['DEF2020_10000'].values) + np.nanmax(fCovidF['DEF2020_10000'].values) * 0.1 ])\n",
    "\n",
    "\n",
    "# formateamos la grilla\n",
    "ax.grid(False)\n",
    "\n",
    "# seteamos leyendas y título\n",
    "ax.set_xlabel('Semana')\n",
    "ax.set_ylabel('Defunciones x 100.000 hab.')\n",
    "ax.set_title('Evolución de defunciones promedio por cada 100.000 vs COVID-19 versus 2020 (ESTIMACION EN BASE A CERTIFICADO)')\n",
    "\n",
    "#tamaño del grafico\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "# color de los ejes \n",
    "ax.spines['bottom'].set_color('#cccccc')\n",
    "ax.spines['top'].set_color('#cccccc') \n",
    "ax.spines['right'].set_color('white')\n",
    "ax.spines['left'].set_color('white')\n",
    "ax.legend(('tasa mortalidad promedio histórica x 100.000 habitantes', 'tasa mortalidad (COVID19 + Histórica) x 100.000 habitantes',\\\n",
    "          'tasa de mortalidad real 2020 x 100.000 hab (APROXIMACIÓN)')\n",
    "          , loc='lower left', shadow=False, fontsize = 13)\n",
    "\n",
    "plt.text(fCovidF['week'][len(fCovidF)] + 0.05, fCovidF['DEF2020_10000'][len(fCovidF)], round(fCovidF['DEF2020_10000'][len(fCovidF)], 2)-1, color = 'blue')\n",
    "plt.text(fCovidF['week'][16] + 0.05, fCovidF['DEF2020_10000'][16], round(fCovidF['DEF2020_10000'][16], 2), color = 'blue')\n",
    "plt.text(fCovidF['week'][len(fCovidF)] + 0.05, fCovidF['DEFCOVID_10000'][len(fCovidF)], round(fCovidF['DEFCOVID_10000'][len(fCovidF)], 2), color = 'red')\n",
    "plt.text(fCovidF['week'][len(fCovidF)] + 0.05, fCovidF['mean'][len(fCovidF)], round(fCovidF['mean'][len(fCovidF)], 2), color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo interpretar el gráfico?\n",
    "La serie de color negro corresponde a las defunciones promedio diaria desde 1990 a 2017 por cada 10.000 habitantes en Chile\n",
    "La serie roja es una serie compuesta que a partir del primer reporte de COVID-19 emitido oficialmente por el MINSAL comienza a tener data. La combinación es la suma de la serie negra con la serie de defunciones por COVID-19 por cada 10.000 habitantes diarias. Es decir, muestra cuanto ha afectado el COVID-19 a la tasa de mortalidad promedio, asumiendo que la tasa de mortalidad de aquellos quienes fallecieron por razones distintas al COVID-19 sigue la tendencia promedio. \n",
    "\n",
    "Además en gris se pueden ver los límites del intervalo de confianza de 95% para la serie histórica. En rojo claro, el intervalo de confianza para la serie combinada de histórico + COVID-19\n",
    "\n",
    "#### Como se puede apreciar se presentan diferencias significativas entre la serie real 2020 versus la combinada, el problema es que, el error que tenemos de 8,3% no explicaría esta diferencia, sin embargo, como vemos este año han habido inscripciones de defunciones semanales en una mayor cantidad que las defunciones reales semanales promedio, sin embargo estas no van al alza, sino que han sido superiores durante gran parte de las semanas del año, y esto podría estar explicado porque la serie histórica solo llega hasta 2017. Para evitar la distorsión de comparar un proxy con un dato real hice uso de la serie histórica de certificados y es lo que presenta a continuación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis usando como base histórica los datos de Certificados"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A modo de ejercicio analítico, y con la finalidad de eliminar la distorsión que se produce entre las series histórica real y la de certificados, realicé el mismo gráfico reemplazando la serie histórica de defunciones reales por la serie histórica de certificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hacemos una copia de la serie que ocuparemos y aplicamos las trasnfromaciones necesarias\n",
    "histCert = toplot.copy()\n",
    "histCert = histCert.merge(proyPobla, how = 'left', left_on = 'AÑO', right_on = 'ANIO')\n",
    "histCert['PROXY_10000'] = round(histCert['PROXY'] / histCert['POBLACION'] * 100000, 2)\n",
    "hCA = histCert.groupby(['week'])['PROXY_10000'].agg(['mean', 'count', 'std']).reset_index()\n",
    "\n",
    "hCA['hi'] = hCA['mean'] + (1.96 * hCA['std'] / np.sqrt(hCA['count']))\n",
    "hCA['low'] = hCA['mean'] - (1.96 * hCA['std'] / np.sqrt(hCA['count']))\n",
    "\n",
    "dfcovidint = temp.copy()\n",
    "dfcovidint['week'] = dfcovidint['week'].astype(int)\n",
    "dfcp = hCA.merge(dfcovidint, how = 'left', left_on = 'week', right_on = 'week')\n",
    "\n",
    "dfcp['DEFCOVID_10000'] = dfcp['mean'] + dfcp['DEFCOVID_10000']\n",
    "dfcp['hiCov'] = (dfcp['hi'] - dfcp['mean'] + dfcp['DEFCOVID_10000'])\n",
    "dfcp['lowCov'] = (dfcp['DEFCOVID_10000'] - (dfcp['mean'] - dfcp['low']))\n",
    "\n",
    "dfcpf = df2020C.merge(dfcp, how = 'left', left_on = 'week', right_on = 'week')\n",
    "dfcpf.index = np.arange(1, len(dfcpf) + 1)\n",
    "dfcpf = dfcpf[:20][:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gráfico 4: Evolución de inscripciones de defunciones promedio (2010 -2019) por cada 100.000 vs COVID-19 versus 2020 (Datos de certificado de defunción)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# GRÁFICO 4\n",
    "#--------------------------------------------\n",
    "# finalmente graficamos con pyplot, sientase libre cualquiera de usar algo más fancy\n",
    "\n",
    "#Librerías necesarias\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#inciamos el gráfico y sus ejes\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot('week', 'mean', data=dfcpf, color='black')\n",
    "ax.plot('week', 'DEFCOVID_10000', data=dfcpf, color='red')\n",
    "ax.plot('week', 'DEF2020_10000', data=dfcpf, color='blue')\n",
    "\n",
    "\n",
    "ax.fill_between(dfcpf.index, dfcpf.low, dfcpf.hi, facecolor='grey', alpha=.2)\n",
    "ax.fill_between(dfcpf.index, dfcpf.lowCov, dfcpf.hiCov, facecolor='red', alpha=.2)\n",
    "\n",
    "# delimitamos el eje y\n",
    "ax.set_ylim([0, np.nanmax(dfcpf['DEF2020_10000'].values) + np.nanmax(dfcpf['DEF2020_10000'].values) * 0.1 ])\n",
    "\n",
    "\n",
    "# formateamos la grilla\n",
    "ax.grid(False)\n",
    "\n",
    "# seteamos leyendas y título\n",
    "ax.set_xlabel('Semana')\n",
    "ax.set_ylabel('Certificados de defunciones x 100.000 hab.')\n",
    "ax.set_title('Evolución de inscripciones de defunciones promedio (2010 -2019) por cada 100.000 vs COVID-19 versus 2020 (Datos de certificado de defunción)')\n",
    "\n",
    "#tamaño del grafico\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "# color de los ejes \n",
    "ax.spines['bottom'].set_color('#cccccc')\n",
    "ax.spines['top'].set_color('#cccccc') \n",
    "ax.spines['right'].set_color('white')\n",
    "ax.spines['left'].set_color('white')\n",
    "ax.legend(('tasa inscripciones promedio histórica x 100.000 habitantes', 'tasa mortalidad (COVID19 + Histórica) x 100.000 habitantes',\\\n",
    "          'tasa de inscripciones 2020 x 100.000 hab.')\n",
    "          , loc='lower left', shadow=False, fontsize = 13)\n",
    "\n",
    "plt.text(dfcpf['week'][len(dfcpf)] + 0.05, dfcpf['DEF2020_10000'][len(dfcpf)], round(dfcpf['DEF2020_10000'][len(dfcpf)], 2), color = 'blue')\n",
    "plt.text(dfcpf['week'][16] + 0.05, dfcpf['DEF2020_10000'][16], round(dfcpf['DEF2020_10000'][16], 2), color = 'blue')\n",
    "plt.text(dfcpf['week'][len(dfcpf)] + 0.05, dfcpf['DEFCOVID_10000'][len(dfcpf)], round(dfcpf['DEFCOVID_10000'][len(dfcpf)], 2), color = 'red')\n",
    "plt.text(dfcpf['week'][len(dfcpf)] + 0.05, dfcpf['mean'][len(dfcpf)], round(dfcpf['mean'][len(dfcpf)], 2), color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos en el gráfico 4, las series se acercaron, si lo comparamos con el gráfico 3, sin embargo 2020 sigue estando por sobre la serie histórica en varias semanas y aunque no pareciera tener una tendencia al alza, es muy prematuro aseverarlo con certeza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Por qué es importante este gráfico?\n",
    "\n",
    "El efecto de la pandemia sobre la tasa de mortalidad nos puede dar luces del impacto de esta enfermedad sobre el sistema de salud, y con ello tomar medidas más estrictas en base a este indicador.\n",
    "La verdad me sorporendí con los pocos datos que existen sobre mortalidad en el mundo, es difícil encontrar datos, en otros paises sudamericanos, incluso USA, pero en Europa, por suerte, es distinto.\n",
    "Encontré las cifras de defunciones generales semanales desde 2010 a marzo 2020 de Inglaterra y Gáles, así como sus cifras de defunciones debido a COVID.\n",
    "Con los datos descritos, ya es posible replicar el análisis, y quiero mostrarles la razón de que sea importante revisar este indicador\n",
    "\n",
    "https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/deaths/datasets/weeklyprovisionalfiguresondeathsregisteredinenglandandwales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "urllib.request.urlretrieve('https://www.ons.gov.uk/file?uri=%2fpeoplepopulationandcommunity%2fbirthsdeathsandmarriages%2fdeaths%2fdatasets%2fweeklyprovisionalfiguresondeathsregisteredinenglandandwales%2f2010/publishedweek2010.xls', \"2010.xls\")\n",
    "urllib.request.urlretrieve('https://www.ons.gov.uk/file?uri=%2fpeoplepopulationandcommunity%2fbirthsdeathsandmarriages%2fdeaths%2fdatasets%2fweeklyprovisionalfiguresondeathsregisteredinenglandandwales%2f2011/publishedweek2011.xls', \"2011.xls\")\n",
    "urllib.request.urlretrieve('https://www.ons.gov.uk/file?uri=%2fpeoplepopulationandcommunity%2fbirthsdeathsandmarriages%2fdeaths%2fdatasets%2fweeklyprovisionalfiguresondeathsregisteredinenglandandwales%2f2012/publishedweek2012.xls', \"2012.xls\")\n",
    "urllib.request.urlretrieve('https://www.ons.gov.uk/file?uri=%2fpeoplepopulationandcommunity%2fbirthsdeathsandmarriages%2fdeaths%2fdatasets%2fweeklyprovisionalfiguresondeathsregisteredinenglandandwales%2f2013/publishedweek2013.xls', \"2013.xls\")\n",
    "urllib.request.urlretrieve('https://www.ons.gov.uk/file?uri=%2fpeoplepopulationandcommunity%2fbirthsdeathsandmarriages%2fdeaths%2fdatasets%2fweeklyprovisionalfiguresondeathsregisteredinenglandandwales%2f2014/publishedweek2014.xls', \"2014.xls\")\n",
    "urllib.request.urlretrieve('https://www.ons.gov.uk/file?uri=%2fpeoplepopulationandcommunity%2fbirthsdeathsandmarriages%2fdeaths%2fdatasets%2fweeklyprovisionalfiguresondeathsregisteredinenglandandwales%2f2015/publishedweek2015.xls', \"2015.xls\")\n",
    "urllib.request.urlretrieve('https://www.ons.gov.uk/file?uri=%2fpeoplepopulationandcommunity%2fbirthsdeathsandmarriages%2fdeaths%2fdatasets%2fweeklyprovisionalfiguresondeathsregisteredinenglandandwales%2f2016/publishedweek522016.xls', \"2016.xls\")\n",
    "urllib.request.urlretrieve('https://www.ons.gov.uk/file?uri=%2fpeoplepopulationandcommunity%2fbirthsdeathsandmarriages%2fdeaths%2fdatasets%2fweeklyprovisionalfiguresondeathsregisteredinenglandandwales%2f2017/publishedweek522017.xls', \"2017.xls\")\n",
    "urllib.request.urlretrieve('https://www.ons.gov.uk/file?uri=%2fpeoplepopulationandcommunity%2fbirthsdeathsandmarriages%2fdeaths%2fdatasets%2fweeklyprovisionalfiguresondeathsregisteredinenglandandwales%2f2018/publishedweek522018withupdatedrespiratoryrow.xls', \"2018.xls\")\n",
    "urllib.request.urlretrieve('https://www.ons.gov.uk/file?uri=%2fpeoplepopulationandcommunity%2fbirthsdeathsandmarriages%2fdeaths%2fdatasets%2fweeklyprovisionalfiguresondeathsregisteredinenglandandwales%2f2019/publishedweek522019.xls', \"2019.xls\")\n",
    "urllib.request.urlretrieve('https://www.ons.gov.uk/file?uri=%2fpeoplepopulationandcommunity%2fbirthsdeathsandmarriages%2fdeaths%2fdatasets%2fweeklyprovisionalfiguresondeathsregisteredinenglandandwales%2f2020/publishedweek202020.xlsx', \"2020.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuentes de población\n",
    "#2010 - 2018 England\n",
    "#https://www.ons.gov.uk/generator?format=xls&uri=/peoplepopulationandcommunity/populationandmigration/populationestimates/timeseries/enpop/pop\n",
    "\n",
    "#2010 - 2018 Wales\n",
    "#https://www.ons.gov.uk/generator?format=xls&uri=/peoplepopulationandcommunity/populationandmigration/populationestimates/timeseries/wapop/pop\n",
    "\n",
    "#proyeccion\n",
    "#https://www.ons.gov.uk/file?uri=%2fpeoplepopulationandcommunity%2fpopulationandmigration%2fpopulationprojections%2fdatasets%2ftablea23principalprojectionenglandandwalespopulationinagegroups%2f2018based/ewpppsumpop18.xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dfhist\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dfConsol = pd.DataFrame()\n",
    "\n",
    "for i in range(0,10):\n",
    "    y = 2010 + i\n",
    "    xls = pd.ExcelFile(str(y) + '.xls')\n",
    "    if (y < 2016):\n",
    "        df = pd.read_excel(xls,'Weekly Figures ' + str(y))\n",
    "    else:\n",
    "        df = pd.read_excel(xls,'Weekly figures ' + str(y))\n",
    "    \n",
    "    df = df[(df['Contents'] == 'Total deaths, all ages')|(df['Contents'] == 'Week number')]\n",
    "    df = df.reset_index().T\n",
    "    df.columns = df.iloc[1]\n",
    "    df = df[2:]\n",
    "    df['year'] = y\n",
    "    dfConsol = dfConsol.append(df)\n",
    "\n",
    "dfConsol = dfConsol.reset_index()\n",
    "dfConsol = dfConsol.drop(columns = {'index'})\n",
    "\n",
    "dfConsol['Total deaths, all ages'] = pd.to_numeric(dfConsol['Total deaths, all ages'], errors='coerce')\n",
    "\n",
    "pop = pd.DataFrame({'year': [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020],\\\n",
    "                   'pop': [55692500, 56171000, 56567800, 56948200, 57408600, 57885400, 58381300, 58744600, 59115809, 59488102, 59829234]})\n",
    "\n",
    "\n",
    "dfConsol = dfConsol.merge(pop, how = 'left', left_on='year', right_on='year')\n",
    "dfConsol['DRx10000'] = dfConsol['Total deaths, all ages'] / dfConsol['pop'] * 10000\n",
    "\n",
    "dTemp = dfConsol.drop(columns = {'year', 'Total deaths, all ages', 'pop'})\n",
    "dfWeekHist = dTemp.groupby(['Week number'], as_index = False)['DRx10000'].agg(['mean', 'count', 'std']).reset_index()\n",
    "dfWeekHist['low'] = dfWeekHist['mean']  - (1.96 * dfWeekHist['std'] / np.sqrt(dfWeekHist['count']))\n",
    "dfWeekHist['hi'] = dfWeekHist['mean']  + (1.96 * dfWeekHist['std'] / np.sqrt(dfWeekHist['count']))\n",
    "dfWeekHist = dfWeekHist.drop(columns = {'std', 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2020\n",
    "xls = pd.ExcelFile('2020.xlsx')\n",
    "df2020 = pd.read_excel(xls,'Weekly figures 2020')\n",
    "\n",
    "df2020 = df2020[(df2020['Contents'] == 'Total deaths, all ages')|(df2020['Contents'] == 'Week number')]\n",
    "df2020 = df2020.reset_index().T\n",
    "df2020.columns = df2020.iloc[1]\n",
    "df2020 = df2020[2:]\n",
    "df2020['year'] = 2020\n",
    "df2020 = df2020.dropna()\n",
    "\n",
    "df2020 = df2020.reset_index()\n",
    "df2020 = df2020.drop(columns = {'index'})\n",
    "\n",
    "df2020['Total deaths, all ages'] = pd.to_numeric(df2020['Total deaths, all ages'], errors='coerce')\n",
    "df2020['pop'] = 59829234\n",
    "df2020['DR2020x10000'] = df2020['Total deaths, all ages'] / df2020['pop'] * 10000\n",
    "\n",
    "df2020 = df2020.drop(columns={'Total deaths, all ages', 'year', 'pop'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfCOVID\n",
    "xls = pd.ExcelFile('2020.xlsx')\n",
    "dfCovid = pd.read_excel(xls,'Covid-19 - Weekly registrations')\n",
    "dfCovid = dfCovid[(dfCovid['Contents'] == 'Deaths involving COVID-19, all ages1')|(dfCovid['Contents'] == 'Week number')]\n",
    "dfCovid = dfCovid.reset_index().T\n",
    "dfCovid.columns = dfCovid.iloc[1]\n",
    "dfCovid = dfCovid[2:]\n",
    "dfCovid['year'] = 2020\n",
    "dfCovid = dfCovid.dropna()\n",
    "\n",
    "dfCovid = dfCovid.reset_index()\n",
    "dfCovid = dfCovid.drop(columns = {'index'})\n",
    "\n",
    "dfCovid['Deaths involving COVID-19, all ages1'] = pd.to_numeric(dfCovid['Deaths involving COVID-19, all ages1'], errors='coerce')\n",
    "dfCovid['pop'] = 59829234\n",
    "dfCovid['DRCOVIDx10000'] = dfCovid['Deaths involving COVID-19, all ages1'] / dfCovid['pop'] * 10000\n",
    "\n",
    "dfCovid = dfCovid.drop(columns={'Deaths involving COVID-19, all ages1', 'year', 'pop'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidacion\n",
    "import math\n",
    "\n",
    "dfEngland = dfCovid.merge(dfWeekHist, how = 'left', left_on = 'Week number', right_on = 'Week number')\n",
    "dfEngland = dfEngland.merge(df2020, how = 'left', left_on = 'Week number', right_on = 'Week number')\n",
    "dfEngland['CompCovid'] = dfEngland['DRCOVIDx10000'] + dfEngland['mean']\n",
    "dfEngland.loc[dfEngland['DRCOVIDx10000'] == 0, 'CompCovid'] = math.nan\n",
    "dfEngland = dfEngland.drop(columns = {'DRCOVIDx10000'})\n",
    "\n",
    "\n",
    "\n",
    "dfEngland.index = np.arange(1, len(dfEngland) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEngland['lowCov'] = math.nan\n",
    "dfEngland.loc[dfEngland['Week number'] > 10, 'lowCov'] = dfEngland['CompCovid'] - (dfEngland['mean'] - dfEngland['low'])\n",
    "\n",
    "dfEngland['hiCov'] = math.nan\n",
    "dfEngland.loc[dfEngland['Week number'] > 10, 'hiCov'] = dfEngland['CompCovid'] + (dfEngland['mean'] - dfEngland['low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# GRÁFICO\n",
    "#--------------------------------------------\n",
    "# finalmente graficamos con pyplot, sientase libre cualquiera de usar algo más fancy\n",
    "\n",
    "#Librerías necesarias\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#inciamos el gráfico y sus ejes\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot('Week number', 'mean', data=dfEngland, color='black')\n",
    "ax.plot('Week number', 'CompCovid', data=dfEngland, color='red')\n",
    "ax.plot('Week number', 'DR2020x10000', data=dfEngland, color='blue')\n",
    "\n",
    "\n",
    "ax.fill_between(dfEngland.index, dfEngland.low, dfEngland.hi, facecolor='grey', alpha=.2)\n",
    "ax.fill_between(dfEngland.index, dfEngland.lowCov, dfEngland.hiCov, facecolor='red', alpha=.2)\n",
    "\n",
    "# delimitamos el eje y\n",
    "ax.set_ylim([0, np.nanmax(dfEngland['DR2020x10000'].values) + np.nanmax(dfEngland['DR2020x10000'].values) * 0.1 ])\n",
    "\n",
    "\n",
    "# formateamos la grilla\n",
    "ax.grid(False)\n",
    "\n",
    "# seteamos leyendas y título\n",
    "ax.set_xlabel('Semana')\n",
    "ax.set_ylabel('defunciones x 10.000 hab.')\n",
    "ax.set_title('Evolución de defunciones promedio por cada 10.000 vs COVID-19 versus 2020')\n",
    "\n",
    "#tamaño del grafico\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "# color de los ejes \n",
    "ax.spines['bottom'].set_color('#cccccc')\n",
    "ax.spines['top'].set_color('#cccccc') \n",
    "ax.spines['right'].set_color('white')\n",
    "ax.spines['left'].set_color('white')\n",
    "ax.legend(('tasa mortalidad promedio histótica x 10.000 habitantes', 'tasa mortalidad (COVID19 + Histórica) x 10.000 habitantes',\\\n",
    "          'tasa de mortalidad real 2020 x 10.000 hab')\n",
    "          , loc='lower left', shadow=False, fontsize = 13)\n",
    "\n",
    "plt.text(dfEngland['Week number'][len(dfEngland['Week number'])] + 0.05, dfEngland['DR2020x10000'][len(dfEngland['DR2020x10000'])], round(dfEngland['DR2020x10000'][len(dfEngland['DR2020x10000'])], 2), color = 'blue')\n",
    "plt.text(dfEngland['Week number'][len(dfEngland['Week number'])] + 0.05, dfEngland['CompCovid'][len(dfEngland['CompCovid'])], round(dfEngland['CompCovid'][len(dfEngland['CompCovid'])], 2), color = 'red')\n",
    "plt.text(dfEngland['Week number'][len(dfEngland['Week number'])] + 0.05, dfEngland['mean'][len(dfEngland['mean'])], round(dfEngland['mean'][len(dfEngland['mean'])], 2), color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "for i in range(0,10):\n",
    "    a = 2010 + i\n",
    "    os.remove(cwd + '\\\\' + str(a) + '.xls')\n",
    "    \n",
    "os.remove(cwd + '\\\\2020.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se aprecia en el gráfico la diferencia entre la suma de las series COVID + Histórica (linea roja) y defunciones reales 2020, es significativa.\n",
    "Frente a esto nos surge las dudas:\n",
    "- ¿A qué se debe esta diferencia?\n",
    "- ¿Se están contabilizando correctamente las defunciones por COVID?\n",
    "- ¿El factor COVID ha incidido en la muerte por otras causas?\n",
    "\n",
    "Y la pregunta principal:\n",
    "- **¿Está pasando esto en Chile?**\n",
    "\n",
    "    ###    Aparentemente no, pero esto sigue siendo un aproximación a los datos reales, que esperemos sean liberados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
